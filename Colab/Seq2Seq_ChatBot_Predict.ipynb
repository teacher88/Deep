{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"mount_file_id":"18jrtmtsNfySLIOFw0H6MpsN1JYea7_V3","authorship_tag":"ABX9TyOFO+01ZJiW/Ybi5358GNk7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install kiwipiepy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BKrMP8hvVIL_","executionInfo":{"status":"ok","timestamp":1747740337066,"user_tz":-540,"elapsed":27849,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"3915e474-e495-4442-ca92-e2d58378c4ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kiwipiepy\n","  Downloading kiwipiepy-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n","Collecting kiwipiepy_model<0.22,>=0.21 (from kiwipiepy)\n","  Downloading kiwipiepy_model-0.21.0.tar.gz (35.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.5/35.5 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from kiwipiepy) (2.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kiwipiepy) (4.67.1)\n","Downloading kiwipiepy-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: kiwipiepy_model\n","  Building wheel for kiwipiepy_model (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kiwipiepy_model: filename=kiwipiepy_model-0.21.0-py3-none-any.whl size=35593192 sha256=cb164999e3d9f877cef2ca41897c4b448f8677bc089aa40126934a195b36178b\n","  Stored in directory: /root/.cache/pip/wheels/b0/16/3d/95053ab5298f0f0f22ffea6de0200b6f24bffb73cab4c1a828\n","Successfully built kiwipiepy_model\n","Installing collected packages: kiwipiepy_model, kiwipiepy\n","Successfully installed kiwipiepy-0.21.0 kiwipiepy_model-0.21.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZCKez91AU0Kc"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, InputLayer\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","import re\n","from kiwipiepy import Kiwi"]},{"cell_type":"markdown","source":["#1.Seq2Seq 모델을 활용한 챗봇\n"],"metadata":{"id":"RFgPUma9rc5r"}},{"cell_type":"markdown","source":["##1-1.데이터 로드 및 확인\n","- 한글 자연어처리 데이터 셋인 Korpora 중 챗봇용 데이터 셋인 KoreanChatbotKorpus를 사용\n","- 데이터 출처 : https://github.com/songys/Chatbot_data\n","- 챗봇 트레이닝용 문답 페어 : 11,823\n","- 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링"],"metadata":{"id":"E8m6Lj7rr9Vx"}},{"cell_type":"code","source":["corpus=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/RNN/data/ChatbotData.csv')\n","corpus.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xqdCa99wU5WS","executionInfo":{"status":"ok","timestamp":1747741144447,"user_tz":-540,"elapsed":87,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"439b44db-d3bf-4539-f8ab-4c2ab809978c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11823, 3)"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["corpus.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fwjOVZfMVZlr","executionInfo":{"status":"ok","timestamp":1747741145542,"user_tz":-540,"elapsed":49,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"122577af-ee7e-4fcc-dba2-63605eadeb61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 11823 entries, 0 to 11822\n","Data columns (total 3 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   Q       11823 non-null  object\n"," 1   A       11823 non-null  object\n"," 2   label   11823 non-null  int64 \n","dtypes: int64(1), object(2)\n","memory usage: 277.2+ KB\n"]}]},{"cell_type":"code","source":["# 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링\n","corpus['label'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":210},"id":"MIkOGwChVmR4","executionInfo":{"status":"ok","timestamp":1747741146487,"user_tz":-540,"elapsed":44,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"0f02d053-ed0d-4546-a74a-0e5ab0bde9a3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["label\n","0    5290\n","1    3570\n","2    2963\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>label</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5290</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3570</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2963</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# 질의 Q와 답변 A로 구성 >> 데이터를 리스트 형태로 저장\n","\n","df_Q=corpus['Q']\n","texts=df_Q.values.tolist()\n","\n","df_A=corpus['A']\n","pairs=df_A.values.tolist()\n","\n","list(zip(texts, pairs))[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQQaYDHWVpS1","executionInfo":{"status":"ok","timestamp":1747741147413,"user_tz":-540,"elapsed":42,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"17703912-8b4f-49c0-aaaa-a0304e056ed3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('12시 땡!', '하루가 또 가네요.'),\n"," ('1지망 학교 떨어졌어', '위로해 드립니다.'),\n"," ('3박4일 놀러가고 싶다', '여행은 언제나 좋죠.'),\n"," ('3박4일 정도 놀러가고 싶다', '여행은 언제나 좋죠.'),\n"," ('PPL 심하네', '눈살이 찌푸려지죠.')]"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["##1-2.데이터 전처리"],"metadata":{"id":"pE16TjnVrtiW"}},{"cell_type":"code","source":["# 1) 데이터 정제 >> 특수문자 제거\n","def clean_sentence(sentence):\n","    sentence=re.sub(r'[^0-9ㄱ-ㅎㅏ-ㅣ가-힣 ]',r'', sentence)\n","    return sentence"],"metadata":{"id":"L1CUWqcsVqzp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clean_sentence('12시 땡^^!??')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"Dilvhx98Vsir","executionInfo":{"status":"ok","timestamp":1747741150406,"user_tz":-540,"elapsed":12,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"a306cfe0-85f8-49e5-d8d3-278587250cc5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'12시 땡'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["clean_sentence('abcef가나다^^$%@12시 땡^^!??')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"wr-cCI34VuTb","executionInfo":{"status":"ok","timestamp":1747741151231,"user_tz":-540,"elapsed":9,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"e14cddc9-3aad-41e8-b314-589e94b3b01b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'가나다12시 땡'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["# 2) 한글 형태소 분석기\n","kiwi=Kiwi()\n","def process_morph(sentence):   # 모프\n","    tokens=kiwi.tokenize(sentence)\n","    morphs=[token.form for token in tokens]\n","    return ' '.join(morphs)   # 추출된 형태소들을 공백(' ')으로 이어붙여 하나의 문자열"],"metadata":{"id":"2SoTppt_Vvkj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##1-3. Seq2Seq모델에 사용되는 3가지 데이터셋을 구성\n","- question : encoder input 데이터셋(질의)\n","- answer_input : decoder input 데이터셋, SOS 토큰을 문장 처음에 추가\n","- answer_output : decoder output 데이터셋, EOS 토큰을 문장 마지막에 추가"],"metadata":{"id":"aSPqMCQEsIJC"}},{"cell_type":"code","source":["# 3) 데이터셋 구성\n","def clean_and_morph(sentence, is_question=True):  # 문장, 질문답변\n","    sentence=clean_sentence(sentence)    #  1) 데이터 정제\n","    sentence=process_morph(sentence)     #  2) 형태소 변환\n","\n","    if is_question:  # 질문\n","        return sentence\n","    else:  #  답변은 시작/끝 토큰을 붙여야 디코더 학습시 유용\n","        return ('<SOS> ' + sentence, sentence + ' <EOS>')    # 공백 Check"],"metadata":{"id":"PEnIjsV4Vw6P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4) 데이터셋 생성\n","def preprocess(texts, pairs):\n","    questions=[]\n","    answer_in=[]\n","    answer_out=[]\n","\n","    # 질의에 대한 전처리\n","    for text in texts:\n","        # 전처리와 morph 수행\n","        question=clean_and_morph(text, is_question=True)  # 3) 호출 >> 1), 2) 호출\n","        questions.append(question)\n","\n","    # 답변에 대한 전처리\n","    for pair in pairs:\n","        # 전처리와 morph 수행\n","        in_, out_ = clean_and_morph(pair, is_question=False)\n","        answer_in.append(in_)\n","        answer_out.append(out_)\n","\n","    return questions, answer_in, answer_out"],"metadata":{"id":"qatUZmLsVyqR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["questions, answer_in, answer_out=preprocess(texts, pairs)   # 4) 호출\n","questions[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7agUuKj2V0Y4","executionInfo":{"status":"ok","timestamp":1747741171161,"user_tz":-540,"elapsed":13380,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"7c072b31-03f3-46f2-a228-15e98f1d728d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['12 시 땡',\n"," '1 지망 학교 떨어지 었 어',\n"," '3 박 4 일 놀 러 가 고 싶 다',\n"," '3 박 4 일 정도 놀 러 가 고 싶 다',\n"," '심 하 네']"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["answer_in[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZV5_to_YV1sf","executionInfo":{"status":"ok","timestamp":1747741171217,"user_tz":-540,"elapsed":23,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"4b22f4b0-a3f9-4ea4-a8b5-f0a41ed725be"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<SOS> 하루 가 또 가 네요',\n"," '<SOS> 위로 하 어 드리 ᆸ니다',\n"," '<SOS> 여행 은 언제나 좋 죠',\n"," '<SOS> 여행 은 언제나 좋 죠',\n"," '<SOS> 눈살 이 찌푸리 어 지 죠']"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["answer_out[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nb_dbfDuV3P_","executionInfo":{"status":"ok","timestamp":1747741171252,"user_tz":-540,"elapsed":30,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"34715ecd-4b5a-4991-f6cc-abb6bb5b2c14"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['하루 가 또 가 네요 <EOS>',\n"," '위로 하 어 드리 ᆸ니다 <EOS>',\n"," '여행 은 언제나 좋 죠 <EOS>',\n"," '여행 은 언제나 좋 죠 <EOS>',\n"," '눈살 이 찌푸리 어 지 죠 <EOS>']"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["##1-4.토큰화"],"metadata":{"id":"vEjgwnVqsUQB"}},{"cell_type":"code","source":["# len(texts)   # 11823개의 데이터 전부를 학습하기에는 램이 부족하기 때문에 데이터 수를 조절\n","train_texts=texts[:5000]\n","train_pairs=pairs[:5000]\n","\n","questions, answer_in, answer_out=preprocess(train_texts, train_pairs)   # 4) 호출\n","len(questions), len(answer_in), len(answer_out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WT3y5wAsV403","executionInfo":{"status":"ok","timestamp":1747741208665,"user_tz":-540,"elapsed":5483,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"c550b423-9eb1-463f-9727-8dda6a4137f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5000, 5000, 5000)"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["# 토큰화를 위해 모든 문장을 합쳐줌\n","all_sentences=questions + answer_in + answer_out\n","a=(' '.join(questions) + ' '.join(answer_in) + ' '.join(answer_out)).split()\n","len(a), len(set(a))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XHR-jLQRWC8P","executionInfo":{"status":"ok","timestamp":1747741211223,"user_tz":-540,"elapsed":68,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"77568418-b737-4843-8dc5-fd09b51fb934"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(120016, 3352)"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["# 토큰의 정의\n","# shift + tab 확인 >> 아무 문자도 제거하지 않음, 대소문자를 구분\n","tokenizer=Tokenizer(filters='', lower=False, oov_token='<OOV>')   # 아무 것도 필터링하지 않음, 대소문자를 구분,\n","\n","# 토근 문장에 대한 Word-Index Vocabulary(단어 사전)을 만듭니다.\n","tokenizer.fit_on_texts(all_sentences)"],"metadata":{"id":"eTn-f2dAV8SX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for word, idx in tokenizer.word_index.items():   # 빈도수 기반으로 idx값 부여\n","    print(f'{word}\\t\\t => \\t{idx}')\n","    if idx > 10:\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bENH6_mUV_sB","executionInfo":{"status":"ok","timestamp":1747741213735,"user_tz":-540,"elapsed":37,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"1e62817a-5b83-466e-d484-a850ea563626"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<OOV>\t\t => \t1\n","하\t\t => \t2\n","어\t\t => \t3\n","이\t\t => \t4\n","<SOS>\t\t => \t5\n","<EOS>\t\t => \t6\n","어요\t\t => \t7\n","보\t\t => \t8\n","는\t\t => \t9\n","세요\t\t => \t10\n","ᆯ\t\t => \t11\n"]}]},{"cell_type":"code","source":["print(len(tokenizer.word_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EadpnIdwWGLB","executionInfo":{"status":"ok","timestamp":1747741215013,"user_tz":-540,"elapsed":48,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"43969f8e-247c-4f9f-e174-c961bb82eb4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3351\n"]}]},{"cell_type":"code","source":["# 텍스트를 시퀀스로 인코딩\n","question_seq=tokenizer.texts_to_sequences(questions)\n","answer_in_seq=tokenizer.texts_to_sequences(answer_in)\n","answer_out_seq=tokenizer.texts_to_sequences(answer_out)\n","# len(question_seq), len(answer_in_seq), len(answer_out_seq)"],"metadata":{"id":"WVwMKp34WJgn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2) 문장의 길이 맞추기\n","MAX_LENGTH=30\n","\n","# 문장이 30을 넘어갈 경우 뒤에서 자르기, 뒤에서부터 0으로 패딩\n","question_pad=pad_sequences(question_seq, maxlen=MAX_LENGTH, truncating='post', padding='post')\n","answer_in_pad=pad_sequences(answer_in_seq, maxlen=MAX_LENGTH, truncating='post', padding='post')\n","answer_out_pad=pad_sequences(answer_out_seq, maxlen=MAX_LENGTH, truncating='post', padding='post')\n","\n","question_pad.shape, answer_in_pad.shape, answer_out_pad.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHCo7_leWMlR","executionInfo":{"status":"ok","timestamp":1747741217303,"user_tz":-540,"elapsed":50,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"6cc0a6e7-a917-454c-b770-243e8c21ef28"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((5000, 30), (5000, 30), (5000, 30))"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["#2.모델 생성"],"metadata":{"id":"dbsedUpGstF5"}},{"cell_type":"markdown","source":["##2-1.Encoder & Decoder & Seq2Seq\n","- 추후 : 추론, 정수형 인코딩 텍스트 변환 등 확장성"],"metadata":{"id":"KxYMDCN4tp1z"}},{"cell_type":"code","source":["class Encoder(tf.keras.Model):\n","    # 객체 생성 시 (한번) >> 초기화\n","    def __init__(self, units, vocab_size, embedding_dim, max_len):\n","        super(Encoder, self).__init__()\n","        self.input_layer=InputLayer(shape=(max_len,))\n","        self.embedding=Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n","        self.dropout=Dropout(0.2)\n","        # self.lstm=LSTM(units, return_state=True,  return_sequences=True) # (32, 10, 64)\n","        self.lstm=LSTM(units, return_state=True) # (32, 10, 64)\n","\n","    # 모델 호출 시 (매번) >> 순전파 로직\n","    def call(self, inputs):\n","        x=self.embedding(inputs)\n","        x=self.dropout(x)\n","        x, hidden_state, cell_state=self.lstm(x)\n","        return [hidden_state, cell_state]"],"metadata":{"id":"htKsa5QLWOFV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Decoder(tf.keras.Model):\n","    # 객체 생성 시 (한번) >> 초기화\n","    def __init__(self, units, vocab_size, embedding_dim, max_len):\n","        super(Decoder, self).__init__()\n","        self.input_layer=InputLayer(shape=(max_len,))\n","        self.embedding=Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n","        self.dropout=Dropout(0.2)\n","        self.lstm=LSTM(units, return_state=True,  return_sequences=True)\n","        self.dense=Dense(vocab_size, activation='softmax')\n","\n","   # 모델 호출 시 (매번) >> 순전파 로직\n","    def call(self, inputs, initial_state):   # 인코더의 마지막 상태를 디코더의 초기 상태\n","        x=self.embedding(inputs)\n","        x=self.dropout(x)\n","        x, hidden_state, cell_state=self.lstm(x, initial_state=initial_state)\n","        x=self.dense(x)\n","        return x, hidden_state, cell_state"],"metadata":{"id":"KdOdak4ZWQDv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Seq2Seq(tf.keras.Model):\n","    def __init__(self, units, vocab_size, embedding_dim, max_len, start_token, end_token):  # (128, 3364, 100, 30, 5, 6)\n","        super(Seq2Seq, self).__init__()\n","        self.start_token=start_token\n","        self.end_token=end_token\n","        self.time_steps=max_len\n","\n","        self.encoder=Encoder(units, vocab_size, embedding_dim, max_len)\n","        self.decoder=Decoder(units, vocab_size, embedding_dim, max_len)\n","\n","    def call(self, inputs, training=True):\n","        if training:   # 학습\n","            encoder_inputs, decoder_inputs=inputs         # 질문문장, 정답문장\n","            context_vector=self.encoder(encoder_inputs)   # 문맥벡터를 얻는다. (h, c) >> 디코더의 초기상태\n","            decoder_outputs, _, _ = self.decoder(inputs=decoder_inputs, initial_state=context_vector)  # 각 시점에서의 softmax 예측값, h, c\n","            return decoder_outputs\n","        else:         # 예측(추론)\n","            context_vector=self.encoder(inputs)  # [hidden_state, cell_state]\n","\n","            # 상수형 : 2차원 / 디코더에 입력할 첫번째 토큰은 <sos>\n","            target_seq=tf.constant([[self.start_token]], dtype=tf.float32)\n","\n","\n","            # 주의). call() 안에서는 numpy 배열 사용하면 안된다.\n","            #      내부적으로 graph 가 형성되어야 하기 때문에 TF 의 TensorArray\n","            results=tf.TensorArray(tf.int32, self.time_steps)  # 단어 하나하나를 예측하여 배열에 담아준다.\n","\n","\n","            # decoder 에 차례대로 토큰 넣고, 결과 내고, 그 결과를 다음 타임스텝에 넣고...를 반복.\n","            # 결과가 <eos> 일때까지!\n","            for i in tf.range(self.time_steps):\n","                decoder_output, decoder_hidden, decoder_cell=self.decoder(target_seq, initial_state=context_vector)\n","\n","                # decoder 출력을 배열에 담기\n","                decoder_output=tf.cast(tf.argmax(decoder_output, axis=-1), dtype=tf.int32)   # 확률 벡터(가장 높은 확률을 가진 인덱스)\n","                # 차원을 바꾸는 이유  (batch_size, sequence_length)\n","                decoder_output=tf.reshape(decoder_output, shape=(1, 1))   # 다음 시점의 디코더 입력\n","                results=results.write(i, decoder_output)                  # 예측된 단어(토큰)를 차례대로 저장\n","\n","                if decoder_output == self.end_token:\n","                    break\n","\n","                # 다음 타임스텝에 전달할 입력토큰\n","                target_seq=decoder_output\n","\n","                 # 다음 타임스텝에 전달할 context vector <- decoder 가 현재 타임스텝에서 출력한 은닉상태와 셀상태로 만들어 준다.\n","                context_vector=[decoder_hidden, decoder_cell]\n","\n","            return tf.reshape(results.stack(), shape=(1, self.time_steps))   # 예측 결과를 한꺼번에 텐서로 묶는다. 1차원형태 패딩으로 채워짐"],"metadata":{"id":"mjYBG0H-WRwL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#3.학습"],"metadata":{"id":"wdwsKLpl29Ft"}},{"cell_type":"code","source":["# 1) 모델 컴파일\n","seq2seq=Seq2Seq(units=128,\n","                vocab_size=len(tokenizer.word_index)+1,\n","                embedding_dim=100,\n","                max_len=MAX_LENGTH,\n","                start_token=tokenizer.word_index['<SOS>'],\n","                end_token=tokenizer.word_index['<EOS>'])\n","\n","seq2seq.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"rlYYZxrgVryQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2) 예측 함수 : 미리 만들어 놓고 학습 중간중간 예측\n","def make_prediction(model, question_inputs):\n","  results=model(inputs=question_inputs, training=False)\n","\n","  # results의 인덱스를 문장으로 변환하기 위해 1차원으로 변환\n","  results=np.asarray(results).reshape(-1)\n","  return results    # 나중에 이 리턴값을 문장으로 변형할 예정."],"metadata":{"id":"Y-CNvmsn3I_t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# index => word 변환\n","# 나중에 딥러닝 모델이 예측을 하게 되면, 숫자값들이 나오는데,\n","# 이를 다시 문자열로 바꾸기 위한 함수를 만들어 두자.\n","\n","def convert_index_to_text(indexes, end_token):\n","  words=[]\n","\n","  # 모든 문장에 대해서 반복\n","  for index in indexes:\n","    if index == end_token: break   # 문장 끝이면 중지\n","\n","    # 사전에 존재하는 단어의 경우 추가 - ERROR 방지 예측시 해당단어가 실제 단어로 등록되어 있을때만 처리\n","    if index > 0 and tokenizer.index_word[index] is not None:   # 0번 인덱스 무시,\n","      words.append(tokenizer.index_word[index])\n","\n","  return ' '.join(words)"],"metadata":{"id":"O-1ICYGW4alu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3) 학습\n","es=EarlyStopping(monitor='loss', patience=5)\n","\n","for epoch in range(2):   # 20\n","  print(f'epoch: {epoch * 10 + 1}...')\n","\n","  seq2seq.fit([question_pad, answer_in_pad],\n","              answer_out_pad, batch_size=10,\n","              epochs=10, callbacks=[es])   # 10\n","\n","    # 랜덤 샘플 추출 : 배열의 길이 내에서 무작위 인덱스 3개\n","  samples=np.random.randint(len(questions), size=3)\n","\n","  for idx in samples:\n","    question_inputs=question_pad[idx]   # 1차원\n","\n","    # 문자예측\n","    results=make_prediction(seq2seq, question_inputs.reshape(1, -1))  # 2차원\n","\n","    # 반환된 인덱스를 문장으로 변환\n","    results=convert_index_to_text(results, tokenizer.word_index['<EOS>'])\n","\n","    print(f'Q: {questions[idx]}')\n","    print(f'A: {results}\\n')\n","    print()"],"metadata":{"id":"YCuT2M4i3bf3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747744259005,"user_tz":-540,"elapsed":1530084,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"590f71d9-112c-4250-888e-a064a3ac8d62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1...\n","Epoch 1/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 110ms/step - accuracy: 0.7768 - loss: 1.2744\n","Epoch 2/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 109ms/step - accuracy: 0.7999 - loss: 1.1291\n","Epoch 3/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 110ms/step - accuracy: 0.8107 - loss: 1.0288\n","Epoch 4/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 110ms/step - accuracy: 0.8212 - loss: 0.9610\n","Epoch 5/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 106ms/step - accuracy: 0.8328 - loss: 0.8957\n","Epoch 6/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 106ms/step - accuracy: 0.8367 - loss: 0.8604\n","Epoch 7/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 107ms/step - accuracy: 0.8449 - loss: 0.8016\n","Epoch 8/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 108ms/step - accuracy: 0.8458 - loss: 0.7804\n","Epoch 9/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 107ms/step - accuracy: 0.8532 - loss: 0.7344\n","Epoch 10/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 107ms/step - accuracy: 0.8572 - loss: 0.7041\n","Q: 눈꺼풀 이 무겁 어\n","A: 저 가 있 잖아요\n","\n","\n","Q: 레고 사 고 싶 은데 비싸 어\n","A: 저 가 있 어요\n","\n","\n","Q: 술 먹 으면 연락 이 안 되 어\n","A: 저 가 있 잖아요\n","\n","\n","epoch: 11...\n","Epoch 1/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 110ms/step - accuracy: 0.8581 - loss: 0.6873\n","Epoch 2/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 110ms/step - accuracy: 0.8639 - loss: 0.6564\n","Epoch 3/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 107ms/step - accuracy: 0.8674 - loss: 0.6323\n","Epoch 4/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 109ms/step - accuracy: 0.8749 - loss: 0.6000\n","Epoch 5/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 108ms/step - accuracy: 0.8782 - loss: 0.5795\n","Epoch 6/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 108ms/step - accuracy: 0.8822 - loss: 0.5575\n","Epoch 7/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 108ms/step - accuracy: 0.8878 - loss: 0.5363\n","Epoch 8/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 107ms/step - accuracy: 0.8886 - loss: 0.5285\n","Epoch 9/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 110ms/step - accuracy: 0.8938 - loss: 0.5096\n","Epoch 10/10\n","\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 111ms/step - accuracy: 0.8956 - loss: 0.4939\n","Q: 늦어지 고 있 는데 변명 이 생각 안 나 어\n","A: 저 도 요\n","\n","\n","Q: 다 육 이 좀 심 어 보 ᆯ까\n","A: 저 도 하 고 싶 네요\n","\n","\n","Q: 앞 으로 나가 지 않 고 이렇 게 만 살 고 싶 어\n","A: 저 도 하 고 싶 네요\n","\n","\n"]}]},{"cell_type":"markdown","source":["#4.예측"],"metadata":{"id":"FTl1N7nLhE7Q"}},{"cell_type":"code","source":["# 전처리 함수 (정제, 형태소변환 등)\n","def make_question(sentence):\n","  sentence=clean_and_morph(sentence)\n","  question_sequence=tokenizer.texts_to_sequences([sentence])\n","  question_padded=pad_sequences(question_sequence, maxlen=MAX_LENGTH, truncating=\"post\", padding=\"post\")\n","  return question_padded"],"metadata":{"id":"dQb2merhs4kB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["make_question('3박4일 놀러가고 싶다')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1W6dC4bOA2n","executionInfo":{"status":"ok","timestamp":1747744279174,"user_tz":-540,"elapsed":50,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"3a7be099-d46f-4777-c19b-c5a812854e50"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 891,  965, 2186,   63,  112,  158,   14,   16,   40,   32,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32)"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["make_question('커피 마시고 싶다.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2572Nq5YODfJ","executionInfo":{"status":"ok","timestamp":1747744280075,"user_tz":-540,"elapsed":33,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"bc628dc2-40fa-4dad-8730-32f8f0c30c5a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[218, 186,  16,  40,  32,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0]], dtype=int32)"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["# 예측 결과\n","def run_chatbot(question):\n","  question_inputs=make_question(question)\n","  results=make_prediction(seq2seq, question_inputs)\n","  results=convert_index_to_text(results, tokenizer.word_index['<EOS>'])\n","  return results\n","\n","run_chatbot('안녕하세요')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"tV1rSuVNOFDQ","executionInfo":{"status":"ok","timestamp":1747744281211,"user_tz":-540,"elapsed":339,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"9ec03fa6-fc19-432f-f1a8-6d8e2e66d185"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'잘 하 ᆯ 수 있 을 거 이 예요'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["while True:\n","  user_input=input('<< 말을 걸어보세요!\\n')\n","  if user_input == 'q': break\n","  print(f'>> 챗봇 응답 : {run_chatbot(user_input)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"thgrsToXQYSo","executionInfo":{"status":"ok","timestamp":1747744488849,"user_tz":-540,"elapsed":162041,"user":{"displayName":"강사","userId":"14202961198716200052"}},"outputId":"57e77e13-f8d7-4cd3-b9d6-497717b40dcb"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["<< 말을 걸어보세요!\n","공부하기 싫어요\n",">> 챗봇 응답 : 저 도 요\n","<< 말을 걸어보세요!\n","배고파\n",">> 챗봇 응답 : 저 도 하 고 싶 네요\n","<< 말을 걸어보세요!\n","게임할래요?\n",">> 챗봇 응답 : 저 도 하 고 싶 네요\n","<< 말을 걸어보세요!\n","q\n"]}]},{"cell_type":"markdown","source":["- 챗봇 seq2 테디 : https://github.com/teddylee777/machine-learning/blob/master/04-TensorFlow2.0/13-chatbot/02-seq2seq-chatbot-attention.ipynb\n","- 챗봇 seq2 티스토리 : https://study-oon.tistory.com/entry/Seq2Seq-%EB%AA%A8%EB%8D%B8%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%B1%97%EB%B4%87-%EC%83%9D%EC%84%B1\n","- https://m.blog.naver.com/sungeun09160/223775192091"],"metadata":{"id":"PzrZAhl6s2JX"}},{"cell_type":"code","source":[],"metadata":{"id":"SEytTak1RoFi"},"execution_count":null,"outputs":[]}]}